{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0b3e2d",
   "metadata": {},
   "source": [
    "# 使用LDA将推特文本提取出主题模型\n",
    "代码是New Bing写的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437c919b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T08:50:23.630678Z",
     "start_time": "2023-03-20T08:50:19.944804Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入相关的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78975235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T08:48:24.543523Z",
     "start_time": "2023-03-20T08:43:49.047176Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "df = pd.read_csv(\"H://课程//毕业论文//data_ori_cleanded//total_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd2a569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T08:50:32.342722Z",
     "start_time": "2023-03-20T08:50:32.308020Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建停用词列表，使用 nltk 自带的英文停用词\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75cd4b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T12:48:27.327254Z",
     "start_time": "2023-03-20T08:50:44.761554Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对文本进行分词、词干化和去停用词，并保存到新的列中\n",
    "df[\"Tweet_content_clean\"] = df[\"Tweet_content\"].apply(lambda x: \" \".join([nltk.stem.PorterStemmer().stem(word) for word in nltk.word_tokenize(x.lower()) if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3435443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T14:47:31.300051Z",
     "start_time": "2023-03-20T14:47:31.300051Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2fedfe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T13:31:46.002718Z",
     "start_time": "2023-03-20T13:31:45.992740Z"
    }
   },
   "outputs": [],
   "source": [
    "def str2list(i):\n",
    "    return i.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "178192b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T13:45:43.286150Z",
     "start_time": "2023-03-20T13:34:02.784025Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Tweet_content_clean = df.Tweet_content_clean.apply(str2list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66552b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T14:00:55.574836Z",
     "start_time": "2023-03-20T13:51:46.690071Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构建词典\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(df[\"Tweet_content_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8845973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T14:34:25.865009Z",
     "start_time": "2023-03-20T14:07:25.692713Z"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 构建文档-词矩阵\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [dictionary\u001b[38;5;241m.\u001b[39mdoc2bow(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTweet_content_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 构建文档-词矩阵\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [dictionary\u001b[38;5;241m.\u001b[39mdoc2bow(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTweet_content_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 构建文档-词矩阵\n",
    "corpus = [dictionary.doc2bow(text) for text in df[\"Tweet_content_clean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 LDA 模型对象，指定主题数为 5\n",
    "lda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06edac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印每个主题的前 10 个关键词\n",
    "lda_model.print_topics(num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef8224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每个文档进行预测，并得到其主题分布\n",
    "topics = lda_model.get_document_topics(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将主题分布转换为 DataFrame 格式，并添加到原数据集中作为新的列\n",
    "topics_df = pd.DataFrame(topics)\n",
    "topics_df.columns = [\"Topic_\" + str(i) for i in range(1,6)]\n",
    "df = pd.concat([df, topics_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关的库\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "# 创建 LDA 可视化对象\n",
    "lda_vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "# 在浏览器中显示可视化结果\n",
    "pyLDAvis.show(lda_vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
