{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883af077",
   "metadata": {},
   "source": [
    "# Hate Speech Detection With Python\n",
    "https://copyassignment.com/hate-speech-detection/\n",
    "\n",
    "## Understanding the data\n",
    "The dataset for building our hate speech detection model is available on www.kaggle.com. The dataset consists of Twitter hate speech detection data, used to research hate-speech detection. The text in the data is classified as hate speech, offensive language, and neither. Due to the nature of the study, it’s important to note that this dataset contains text that can be considered racist, sexist, homophobic, or generally offensive.\n",
    "\n",
    "You can find the dataset for hate speech detection here https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset\n",
    "\n",
    "There are 7 columns in the hate speech detection dataset. They are index, count, hate_speech, offensive_language, neither, class and tweet. The description of the column is as follows.\n",
    "\n",
    "- index – This column has the index value\n",
    "- count– It has the number of users who coded each tweet\n",
    "- hate_speech – This column has the number of users who judged the tweet to be hate speech\n",
    "- offensive_language – It has the number of users who judged the tweet to be offensive\n",
    "- neither – This has the number of users who judged the tweet to be neither offensive nor non-offensive\n",
    "- class – it has a class label for the majority of the users, in which 0 denotes hate speech, 1 means offensive language and 2 denotes neither of them.\n",
    "- tweet – This column has the text tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5c19278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:02:28.826625Z",
     "start_time": "2023-02-25T09:02:28.812854Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn. feature_extraction. text import CountVectorizer\n",
    "from sklearn. feature_extraction. text import TfidfVectorizer\n",
    "from sklearn. model_selection import train_test_split\n",
    "from sklearn. tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcf322be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:02:32.022510Z",
     "start_time": "2023-02-25T09:02:31.029651Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\范宏瑞\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk. download('stopwords')\n",
    "from nltk. corpus import stopwords\n",
    "stopword=set(stopwords.words('english'))\n",
    "stemmer = nltk. SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b47a53ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:02:33.490878Z",
     "start_time": "2023-02-25T09:02:33.423500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "data = pd. read_csv(\"labeled_data.csv\")\n",
    "#To preview the data\n",
    "print(data. head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769cc8c",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "In Data preprocessing, we prepare the raw data and make it suitable for a machine learning model. It is the first and crucial step while creating a machine learning model. When creating a machine learning project, it is not always a case that we come across clean and formatted data. And while doing any operation with data, it is mandatory to clean it and put it in a formatted way. So for this, we use the data preprocessing task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9d16cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:02:39.069924Z",
     "start_time": "2023-02-25T09:02:39.047438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "\n",
      "                         labels  \n",
      "0  No Hate and Offensive Speech  \n",
      "1              Offensive Speech  \n",
      "2              Offensive Speech  \n",
      "3              Offensive Speech  \n",
      "4              Offensive Speech  \n"
     ]
    }
   ],
   "source": [
    "data[\"labels\"] = data[\"class\"]. map({0: \"Hate Speech\", 1: \"Offensive Speech\", 2: \"No Hate and Offensive Speech\"})\n",
    "data = data[[\"tweet\", \"labels\"]]\n",
    "print(data. head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f827ca4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:02:57.272750Z",
     "start_time": "2023-02-25T09:02:52.075199Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def clean (text):\n",
    "    text = str (text). lower()\n",
    "    text = re. sub('[.?]', '', text) \n",
    "    text = re. sub('https?://\\S+|www.\\S+', '', text)\n",
    "    text = re. sub('<.?>+', '', text)\n",
    "    text = re. sub('[%s]' % re. escape(string. punctuation), '', text)\n",
    "    text = re. sub('\\n', '', text)\n",
    "    text = re. sub('\\w\\d\\w', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \". join(text)\n",
    "    text = [stemmer. stem(word) for word in text. split(' ')]\n",
    "    text=\" \". join(text)\n",
    "    return text\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"]. apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc60c2cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:03:26.965775Z",
     "start_time": "2023-02-25T09:03:26.950814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Offensive Speech                19190\n",
       "No Hate and Offensive Speech     4163\n",
       "Hate Speech                      1430\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40780468",
   "metadata": {},
   "source": [
    "这是一个不平衡分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb2dcdc",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "The next important step is to explore the dataset and divide the dataset into training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eeab79",
   "metadata": {},
   "source": [
    "NLP三种词袋模型CountVectorizer/TFIDF/HashVectorizer\n",
    "https://zhuanlan.zhihu.com/p/268886634"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f4f270b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:10:05.248546Z",
     "start_time": "2023-02-25T09:10:05.232857Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np. array(data[\"tweet\"])\n",
    "y = np. array(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bcd3472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:11:27.414851Z",
     "start_time": "2023-02-25T09:11:27.009487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv. fit_transform(x)\n",
    "# Splitting the Data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "#StratifiedKFold 分层k折\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb7dcfbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:11:53.127185Z",
     "start_time": "2023-02-25T09:11:53.068689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 2411  2412  2413 ... 24780 24781 24782] TEST: [   0    1    2 ... 2680 2684 2687]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [2411 2412 2413 ... 5098 5100 5101]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [4015 4030 4036 ... 7734 7735 7736]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [ 5407  5417  5442 ... 10228 10229 10230]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [ 6712  6713  6732 ... 12574 12575 12576]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [ 8991  9007  9011 ... 15044 15045 15047]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [12026 12038 12052 ... 17500 17502 17504]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [14984 14985 15009 ... 19942 19946 19948]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [18477 18483 18499 ... 22391 22392 22393]\n",
      "TRAIN: [    0     1     2 ... 22391 22392 22393] TEST: [21784 21837 21843 ... 24780 24781 24782]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "489618f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:13:16.118947Z",
     "start_time": "2023-02-25T09:13:15.703776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 2411  2412  2413 ... 24780 24781 24782] TEST: [   0    1    2 ... 2680 2684 2687]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [2411 2412 2413 ... 5098 5100 5101]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [4015 4030 4036 ... 7734 7735 7736]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [ 5407  5417  5442 ... 10228 10229 10230]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [ 6712  6713  6732 ... 12574 12575 12576]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [ 8991  9007  9011 ... 15044 15045 15047]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [12026 12038 12052 ... 17500 17502 17504]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [14984 14985 15009 ... 19942 19946 19948]\n",
      "TRAIN: [    0     1     2 ... 24780 24781 24782] TEST: [18477 18483 18499 ... 22391 22392 22393]\n",
      "TRAIN: [    0     1     2 ... 22391 22392 22393] TEST: [21784 21837 21843 ... 24780 24781 24782]\n"
     ]
    }
   ],
   "source": [
    "tfv = TfidfVectorizer()\n",
    "X2 = tfv. fit_transform(x)\n",
    "#X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size=0.33, random_state=42)\n",
    "\n",
    "#StratifiedKFold 分层k折\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X2, y)\n",
    "for train_index, test_index in skf.split(X2, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X2_train, X2_test = X2[train_index], X2[test_index]\n",
    "    y2_train, y2_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdeefd6",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "After segregating the data, our next work is to find a good algorithm suited for our model. We can use a Decision tree classifier for building the Hate Speech detection project. Decision Trees are a type of Supervised Machine Learning used mainly for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba6cb9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:14:35.453720Z",
     "start_time": "2023-02-25T09:14:25.629303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model building\n",
    "model = DecisionTreeClassifier()\n",
    "#Training the model\n",
    "model. fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a64c943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:14:48.297889Z",
     "start_time": "2023-02-25T09:14:38.365802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = DecisionTreeClassifier()\n",
    "#Training the model\n",
    "model2. fit(X2_train,y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95785907",
   "metadata": {},
   "source": [
    "## Evaluating the results\n",
    "The final step in machine learning model building is prediction. In this step, we can measure how well our model performs for the test input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5754513d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:14:49.750214Z",
     "start_time": "2023-02-25T09:14:49.728242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Offensive Speech', 'Offensive Speech', 'Offensive Speech', ...,\n",
       "       'Offensive Speech', 'Offensive Speech',\n",
       "       'No Hate and Offensive Speech'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the model\n",
    "y_pred = model. predict (X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f627e171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:14:51.137278Z",
     "start_time": "2023-02-25T09:14:51.114821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Offensive Speech', 'Offensive Speech', 'Offensive Speech', ...,\n",
       "       'Offensive Speech', 'Offensive Speech',\n",
       "       'No Hate and Offensive Speech'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the model\n",
    "y2_pred = model2. predict (X2_test)\n",
    "y2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "044708c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:14:52.433208Z",
     "start_time": "2023-02-25T09:14:52.379183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8829701372074253\n",
      "0.8829701372074253\n",
      "0.8829701372074253\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score of our model\n",
    "from sklearn. metrics import accuracy_score, f1_score, recall_score\n",
    "print (accuracy_score (y_test,y_pred))\n",
    "print (f1_score (y_test,y_pred, average='micro'))\n",
    "print (recall_score (y_test,y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef3303d",
   "metadata": {},
   "source": [
    "### skmetrics输出acc、precision、recall、f1值相同的问题\n",
    "average='micro'的原理是：\n",
    "把每个类别的TP、FP、FN先相加，再把这个问题当成二分类来进行计算\n",
    "\n",
    "在某一类中被判断成FP的样本，在其他类中一定是FN的样本\n",
    "\n",
    "解决方法的话就是换一种平均的方法average = 'macro’\n",
    "\n",
    "这种方法是对于不同的类分别计算评估指标，然后加起来求平均\n",
    "https://blog.csdn.net/fujikoo/article/details/119926390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e17b8682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:14:56.408930Z",
     "start_time": "2023-02-25T09:14:56.370103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8829701372074253\n",
      "0.6993934215587227\n",
      "0.6893382531572995\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score of our model\n",
    "from sklearn. metrics import accuracy_score, f1_score, recall_score\n",
    "print (accuracy_score (y_test,y_pred))\n",
    "print (f1_score (y_test,y_pred, average='macro'))\n",
    "print (recall_score (y_test,y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "58935520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:14:59.350278Z",
     "start_time": "2023-02-25T09:14:59.306312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8829701372074253\n",
      "0.6835371701368548\n",
      "0.6733350080959513\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score of our model2\n",
    "from sklearn. metrics import accuracy_score\n",
    "print (accuracy_score (y2_test,y2_pred))\n",
    "print (f1_score (y2_test,y2_pred, average='macro'))\n",
    "print (recall_score (y2_test,y2_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be3af06d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:15:02.069845Z",
     "start_time": "2023-02-25T09:15:02.050896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Hate and Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "#Predicting the outcome\n",
    "inp = \"You are too bad and I dont like your attitude\"\n",
    "inp = cv.transform([inp]).toarray()\n",
    "print(model.predict(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13463576",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this article, we have built a project for Hate Speech detection using Machine Learning. Hate speech is one of the serious issues we see on social media platforms like Facebook and Twitter. Hope you enjoyed this article by building a project to detect hate speech with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24feee63",
   "metadata": {},
   "source": [
    "# Use Russia-Ukraine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dc5e2c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:25:05.747030Z",
     "start_time": "2023-02-25T05:25:05.682706Z"
    }
   },
   "outputs": [],
   "source": [
    "#\"H:\\课程\\毕业论文\\cleaned\\tweet_ids_day_2022-2-22_clean.csv\"\n",
    "df = pd.read_csv(\"H:/课程/毕业论文/cleaned/tweet_ids_day_2022-2-22_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e923db76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:30:01.615127Z",
     "start_time": "2023-02-25T05:30:01.598217Z"
    }
   },
   "outputs": [],
   "source": [
    "#model1: cv+ decision tree\n",
    "def hate_detection_1(text):\n",
    "    text = clean(text)\n",
    "    inp = cv.transform([text]).toarray()\n",
    "    result = model.predict(inp)\n",
    "    return result[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f16dc6fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:54.695143Z",
     "start_time": "2023-02-25T05:31:54.676480Z"
    }
   },
   "outputs": [],
   "source": [
    "#model1: tf-idf+ decision tree\n",
    "def hate_detection_2(text):\n",
    "    text = clean(text)\n",
    "    inp = tfv.transform([text]).toarray()\n",
    "    result = model2.predict(inp)\n",
    "    return result[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ffcbea1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:01.421557Z",
     "start_time": "2023-02-25T05:31:00.220085Z"
    }
   },
   "outputs": [],
   "source": [
    "df['is_Hate_m1'] = df['Tweet_content'].apply(hate_detection_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f7bed9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:32:09.859481Z",
     "start_time": "2023-02-25T05:32:08.069774Z"
    }
   },
   "outputs": [],
   "source": [
    "df['is_Hate_m2'] = df['Tweet_content'].apply(hate_detection_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c42e456",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:27.165171Z",
     "start_time": "2023-02-25T05:31:27.129527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Hate and Offensive Speech    638\n",
       "Hate Speech                      60\n",
       "Offensive Speech                 44\n",
       "Name: is_Hate_m1, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_Hate_m1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8d85d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:32:16.374091Z",
     "start_time": "2023-02-25T05:32:16.356434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Hate and Offensive Speech    656\n",
       "Offensive Speech                 75\n",
       "Hate Speech                      11\n",
       "Name: is_Hate_m2, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_Hate_m2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "733338f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:35:23.352313Z",
     "start_time": "2023-02-25T05:35:23.334096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'russian troops enter eastern ukraine russia ukraine ukraineconflict ukraina war russiaukraine russiainvadedukraine ukrainecrisis biden putinswar russiaukrainecrisis russiaucraina ukrainerussiacrisis'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['is_Hate_m1']==\"Hate Speech\"].Tweet_content.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e72e75ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T13:15:26.683324Z",
     "start_time": "2023-02-25T13:15:26.659439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the whole world: mr. putin what you are doing is wrong. putin: ? ukraina russiaukraineconflict'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['is_Hate_m2']==\"Hate Speech\"].Tweet_content.iloc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0d65a9",
   "metadata": {},
   "source": [
    "# 尝试换一下模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a49a2b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T06:10:20.069075Z",
     "start_time": "2023-02-25T06:10:19.953902Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#让我们从朴素的贝叶斯分类器开始，它为该任务提供了一个很好的基准。 scikit-learn包含此分类器的多种变体； 多项式最适合单词计数：\n",
    "clf = MultinomialNB().fit(X2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b49f0093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T06:35:59.843320Z",
     "start_time": "2023-02-25T06:35:59.830752Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82048d4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T06:36:38.138443Z",
     "start_time": "2023-02-25T06:36:37.975552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7901944002934344\n",
      "0.3516003992102368\n",
      "0.3650300415199313\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score (y2_test,predicted))\n",
    "print (f1_score (y2_test,predicted, average='macro'))\n",
    "print (recall_score (y2_test,predicted, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8aaf8bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T06:43:30.353233Z",
     "start_time": "2023-02-25T06:43:30.327858Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np. array(data[\"tweet\"])\n",
    "y = np. array(data[\"labels\"])\n",
    "# Splitting the Data\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce01d89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T06:43:33.345502Z",
     "start_time": "2023-02-25T06:43:33.325808Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a07d232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T06:43:44.606997Z",
     "start_time": "2023-02-25T06:43:44.103326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(x3_train,y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10457cd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T06:48:56.589596Z",
     "start_time": "2023-02-25T06:48:55.866599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8141582100501283\n",
      "0.43542201045292966\n",
      "0.4214843275280216\n"
     ]
    }
   ],
   "source": [
    "#线性支持向量机（SVM）\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(x3_train, y3_train)\n",
    "y3_pred = text_clf.predict(x3_test)\n",
    "print (accuracy_score (y3_test,y3_pred))\n",
    "print (f1_score (y3_test,y3_pred, average='macro'))\n",
    "print (recall_score (y3_test,y3_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeafb294",
   "metadata": {},
   "source": [
    "换了以后还不如之前的呢……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54b3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
