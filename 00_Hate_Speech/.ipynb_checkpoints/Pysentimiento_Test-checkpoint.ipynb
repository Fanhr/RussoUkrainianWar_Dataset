{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f7f30c",
   "metadata": {},
   "source": [
    "# 使用pysentimiento进行推文处理与仇恨言论检测\n",
    "https://github.com/pysentimiento/pysentimiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84dd49",
   "metadata": {},
   "source": [
    "## 官方示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6156d3a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T07:26:33.445915Z",
     "start_time": "2023-03-02T07:19:46.465207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86177300517f4faaae70a231df79b1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/925 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\范宏瑞\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988b4550757347b280c3e15fb4dcd48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6568811210f1440481ed0dfcea802de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa78ec0960e4323828b406309444961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce98239a5f94c90b8cec0658ef7209b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99da37ea4004a639265b18a85df441b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-emotion-analysis\\snapshots\\64046df9cc41eab40e1ecde7d2b7fb42b971be5b\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a02ec78d0642fda78c0a1af270d6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-emotion-analysis\\snapshots\\64046df9cc41eab40e1ecde7d2b7fb42b971be5b\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-emotion-analysis.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7791f084627d429eafac731e81724499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/295 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-emotion-analysis\\snapshots\\64046df9cc41eab40e1ecde7d2b7fb42b971be5b\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bf0f6f6960433a91880a71111a0c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c153a03d6be4a80a6fa9f423e3d49a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f62efa121d4c45a737f56a2b409d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3173e11051d54560a77f60a801f87c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-emotion-analysis\\snapshots\\64046df9cc41eab40e1ecde7d2b7fb42b971be5b\\vocab.txt\n",
      "loading file bpe.codes from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-emotion-analysis\\snapshots\\64046df9cc41eab40e1ecde7d2b7fb42b971be5b\\bpe.codes\n",
      "loading file added_tokens.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-emotion-analysis\\snapshots\\64046df9cc41eab40e1ecde7d2b7fb42b971be5b\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-emotion-analysis\\snapshots\\64046df9cc41eab40e1ecde7d2b7fb42b971be5b\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-emotion-analysis\\snapshots\\64046df9cc41eab40e1ecde7d2b7fb42b971be5b\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-emotion-analysis\\snapshots\\64046df9cc41eab40e1ecde7d2b7fb42b971be5b\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "Adding <mask> to the vocabulary\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca322aad8e374da0827382ce214a3492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/956 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--robertuito-hate-speech\\snapshots\\db125ee7be2ad74457b900ae49a7e0f14f7a496c\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-hate-speech\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"hateful\",\n",
      "    \"1\": \"targeted\",\n",
      "    \"2\": \"aggressive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"aggressive\": 2,\n",
      "    \"hateful\": 0,\n",
      "    \"targeted\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30002\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b66763d3cde42799c22d5b5c0bf49c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--robertuito-hate-speech\\snapshots\\db125ee7be2ad74457b900ae49a7e0f14f7a496c\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/robertuito-hate-speech.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8858c6dae12d4da6a642fc1b3f6aca01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713cbb1e32f94d1cbdd36b1bf448cb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0308736e33f44fb2a9688e1729677ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--robertuito-hate-speech\\snapshots\\db125ee7be2ad74457b900ae49a7e0f14f7a496c\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--robertuito-hate-speech\\snapshots\\db125ee7be2ad74457b900ae49a7e0f14f7a496c\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--robertuito-hate-speech\\snapshots\\db125ee7be2ad74457b900ae49a7e0f14f7a496c\\tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=['hateful', 'targeted', 'aggressive'], probas={hateful: 0.987, targeted: 0.987, aggressive: 0.973})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "\n",
    "analyzer.predict(\"Qué gran jugador es Messi\")\n",
    "# returns AnalyzerOutput(output=POS, probas={POS: 0.998, NEG: 0.002, NEU: 0.000})\n",
    "analyzer.predict(\"Esto es pésimo\")\n",
    "# returns AnalyzerOutput(output=NEG, probas={NEG: 0.999, POS: 0.001, NEU: 0.000})\n",
    "analyzer.predict(\"Qué es esto?\")\n",
    "# returns AnalyzerOutput(output=NEU, probas={NEU: 0.993, NEG: 0.005, POS: 0.002})\n",
    "\n",
    "analyzer.predict(\"jejeje no te creo mucho\")\n",
    "# AnalyzerOutput(output=NEG, probas={NEG: 0.587, NEU: 0.408, POS: 0.005})\n",
    "\"\"\"\n",
    "Emotion Analysis in English\n",
    "\"\"\"\n",
    "\n",
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"en\")\n",
    "\n",
    "emotion_analyzer.predict(\"yayyy\")\n",
    "# returns AnalyzerOutput(output=joy, probas={joy: 0.723, others: 0.198, surprise: 0.038, disgust: 0.011, sadness: 0.011, fear: 0.010, anger: 0.009})\n",
    "emotion_analyzer.predict(\"fuck off\")\n",
    "# returns AnalyzerOutput(output=anger, probas={anger: 0.798, surprise: 0.055, fear: 0.040, disgust: 0.036, joy: 0.028, others: 0.023, sadness: 0.019})\n",
    "\n",
    "\"\"\"\n",
    "Hate Speech (misogyny & racism)\n",
    "\"\"\"\n",
    "hate_speech_analyzer = create_analyzer(task=\"hate_speech\", lang=\"es\")\n",
    "\n",
    "hate_speech_analyzer.predict(\"Esto es una mierda pero no es odio\")\n",
    "# returns AnalyzerOutput(output=[], probas={hateful: 0.022, targeted: 0.009, aggressive: 0.018})\n",
    "hate_speech_analyzer.predict(\"Esto es odio porque los inmigrantes deben ser aniquilados\")\n",
    "# returns AnalyzerOutput(output=['hateful'], probas={hateful: 0.835, targeted: 0.008, aggressive: 0.476})\n",
    "\n",
    "hate_speech_analyzer.predict(\"Vaya guarra barata y de poca monta es XXXX!\")\n",
    "# returns AnalyzerOutput(output=['hateful', 'targeted', 'aggressive'], probas={hateful: 0.987, targeted: 0.978, aggressive: 0.969})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64e7af",
   "metadata": {},
   "source": [
    "## 引入第三方测试集验证性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912b22d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T07:28:18.771474Z",
     "start_time": "2023-03-02T07:28:18.380676Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn. feature_extraction. text import CountVectorizer\n",
    "from sklearn. feature_extraction. text import TfidfVectorizer\n",
    "from sklearn. model_selection import train_test_split\n",
    "from sklearn. tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b54c97a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T07:28:31.112748Z",
     "start_time": "2023-03-02T07:28:31.019968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "data = pd. read_csv(\"labeled_data.csv\")\n",
    "#To preview the data\n",
    "print(data. head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643f8239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T07:28:40.122559Z",
     "start_time": "2023-03-02T07:28:40.101619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "\n",
      "                         labels  \n",
      "0  No Hate and Offensive Speech  \n",
      "1              Offensive Speech  \n",
      "2              Offensive Speech  \n",
      "3              Offensive Speech  \n",
      "4              Offensive Speech  \n"
     ]
    }
   ],
   "source": [
    "data[\"labels\"] = data[\"class\"]. map({0: \"Hate Speech\", 1: \"Offensive Speech\", 2: \"No Hate and Offensive Speech\"})\n",
    "data = data[[\"tweet\", \"labels\"]]\n",
    "print(data. head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503594dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T07:29:17.704777Z",
     "start_time": "2023-03-02T07:29:15.926541Z"
    }
   },
   "outputs": [],
   "source": [
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "data[\"tweet\"] = data[\"tweet\"]. apply(preprocess_tweet)#使用pysentimiento预处理推文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd22cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T07:29:21.657957Z",
     "start_time": "2023-03-02T07:29:21.636982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @usuario: As a woman you shouldn't comp...</td>\n",
       "      <td>No Hate and Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!! RT @usuario: boy dats cold...tyga dwn bad ...</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!! RT @usuario Dawg!!! RT @usuario: You ever ...</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!! RT @usuario: @usuario she look like a tranny</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!! RT @usuario: The shit you hear about me mi...</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  !!! RT @usuario: As a woman you shouldn't comp...   \n",
       "1  !!! RT @usuario: boy dats cold...tyga dwn bad ...   \n",
       "2  !!! RT @usuario Dawg!!! RT @usuario: You ever ...   \n",
       "3   !!! RT @usuario: @usuario she look like a tranny   \n",
       "4  !!! RT @usuario: The shit you hear about me mi...   \n",
       "\n",
       "                         labels  \n",
       "0  No Hate and Offensive Speech  \n",
       "1              Offensive Speech  \n",
       "2              Offensive Speech  \n",
       "3              Offensive Speech  \n",
       "4              Offensive Speech  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0479f",
   "metadata": {},
   "source": [
    "使用pysentimiento构建分析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4de90af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T07:37:04.581323Z",
     "start_time": "2023-03-02T07:36:59.481944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--bertweet-hate-speech\\snapshots\\d9925de199f48face0d7026f07c3b492c423bbc0\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/bertweet-hate-speech\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"hateful\",\n",
      "    \"1\": \"targeted\",\n",
      "    \"2\": \"aggressive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"aggressive\": 2,\n",
      "    \"hateful\": 0,\n",
      "    \"targeted\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--bertweet-hate-speech\\snapshots\\d9925de199f48face0d7026f07c3b492c423bbc0\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/bertweet-hate-speech.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "loading file vocab.txt from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--bertweet-hate-speech\\snapshots\\d9925de199f48face0d7026f07c3b492c423bbc0\\vocab.txt\n",
      "loading file bpe.codes from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--bertweet-hate-speech\\snapshots\\d9925de199f48face0d7026f07c3b492c423bbc0\\bpe.codes\n",
      "loading file added_tokens.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--bertweet-hate-speech\\snapshots\\d9925de199f48face0d7026f07c3b492c423bbc0\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--bertweet-hate-speech\\snapshots\\d9925de199f48face0d7026f07c3b492c423bbc0\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\范宏瑞/.cache\\huggingface\\hub\\models--pysentimiento--bertweet-hate-speech\\snapshots\\d9925de199f48face0d7026f07c3b492c423bbc0\\tokenizer_config.json\n",
      "Adding <mask> to the vocabulary\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_analyzer = create_analyzer(task=\"hate_speech\", lang=\"en\")#检测英文\n",
    "\n",
    "output = hate_speech_analyzer.predict(data.tweet[1])\n",
    "output.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d626a7b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-02T07:39:39.236Z"
    }
   },
   "outputs": [],
   "source": [
    "data['predicts'] = data['tweet'].apply(hate_speech_analyzer.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175caf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
