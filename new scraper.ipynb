{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578ce7b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T07:12:22.572705Z",
     "start_time": "2022-11-15T07:12:20.960512Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import queue\n",
    "import threading\n",
    "from IPython.display import clear_output as clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c6555e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T07:14:59.916656Z",
     "start_time": "2022-11-15T07:12:23.999516Z"
    }
   },
   "outputs": [],
   "source": [
    "date_series = [f\"../RussiaUkraine/RussoUkrainianWar_Dataset-main/2022-0{month}/tweet_ids_day_2022-{month}-{date}.txt\"\n",
    "              for month in range(2,10) for date in range(1,32)]\n",
    "dates = []\n",
    "lenths = []\n",
    "for date_data in date_series:\n",
    "    if os.path.exists(date_data):\n",
    "        testset=[]\n",
    "        with open(date_data,'r') as f:\n",
    "            for line in f:\n",
    "                testset.append(line.strip('\\n').split(','))\n",
    "        dates.append(date_data)\n",
    "        lenths.append(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5daee9d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T07:17:02.275504Z",
     "start_time": "2022-11-15T07:17:02.258421Z"
    }
   },
   "outputs": [],
   "source": [
    "sem=threading.Semaphore(20) #限制线程的最大数量20\n",
    "def tweetscraper(j, tweets_list):\n",
    "    with sem:\n",
    "        clear(wait=True)#先清除输出区域，不然会一直打印造成ipynb文件过大\n",
    "        try:\n",
    "            for i,tweet in enumerate(sntwitter.TwitterTweetScraper(j).get_items()):\n",
    "                tweets_list.append([\n",
    "                    tweet.date, tweet.url, tweet.id, tweet.content, tweet.replyCount, tweet.retweetCount, tweet.likeCount,\n",
    "                    tweet.quoteCount, tweet.conversationId, tweet.lang, tweet.source, tweet.sourceUrl, tweet.outlinks, tweet.media,\n",
    "                    tweet.retweetedTweet, tweet.quotedTweet, tweet.inReplyToTweetId, tweet.inReplyToUser, tweet.mentionedUsers, \n",
    "                    tweet.coordinates, tweet.place, tweet.hashtags, tweet.cashtags, #tweet相关的字段\n",
    "                    tweet.user.username, tweet.user.displayname, tweet.user.id, tweet.user.rawDescription, tweet.user.descriptionUrls,\n",
    "                    tweet.user.verified, tweet.user.created,tweet.user.followersCount, tweet.user.friendsCount, tweet.user.statusesCount, \n",
    "                    tweet.user.favouritesCount,tweet.user.listedCount, tweet.user.mediaCount, tweet.user.location, tweet.user.protected,\n",
    "                    tweet.user.linkUrl,tweet.user.profileImageUrl, tweet.user.profileBannerUrl, tweet.user.label ##user相关的字段\n",
    "                    ])\n",
    "            time.sleep(1)\n",
    "            print(len(tweets_list), \"tweets have been scraped\", flush = True)\n",
    "            time.sleep(0.1)\n",
    "        except:\n",
    "            print(\"a mistake have been passed\", flush = True)\n",
    "            time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e3ca14b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T07:22:21.153564Z",
     "start_time": "2022-11-15T07:22:21.137076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471621"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenths[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc20ac02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T10:49:44.277379Z",
     "start_time": "2022-11-15T07:24:10.232926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40145 tweets have been scraped\n",
      "40145 tweets have been scraped\n",
      "40145 tweets have been scraped\n",
      "40145 tweets have been scraped\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 51):\n",
    "    testset = []\n",
    "    with open(dates[i], 'r') as f:\n",
    "        for line in f:\n",
    "            testset.append(line.strip('\\\\n').split(','))\n",
    "    test = []\n",
    "    for j in testset:\n",
    "        test.append(int(j[0]))\n",
    "    # create multi-threads to scrape\n",
    "    threads = []\n",
    "    tweets_list = []\n",
    "    print(dates[i], 'scraper begins')\n",
    "    \n",
    "    for j in test:\n",
    "        threads.append(\n",
    "            threading.Thread(target = tweetscraper, args=(j, tweets_list))\n",
    "            )\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    print(dates[i], 'has been scraped')\n",
    "    \n",
    "    tweets_df = pd.DataFrame(tweets_list, columns=[\n",
    "                                                'Datetime', 'Tweet_url', 'Tweet_id', 'Tweet_content', 'Tweet_reply_count', 'Tweet_retweet_count',\n",
    "                                                'Tweet_like_count', 'Tweet_quote_count', 'Tweet_conversation_id', 'Tweet_language', 'Tweet_source', \n",
    "                                                'Tweet_source_url', 'Tweet_links', 'Tweet_mdeia', 'Tweet_retweeted_tweet', 'Tweet_quoted_tweet', \n",
    "                                                'Tweet_inReplyToTweetId','Tweet_inReplyToUser','Tweet_mentioned_users','Tweet_coordinates', 'Tweet_place', \n",
    "                                                'Tweet_hashtags', 'Tweet_cashtags',#tweet 相关的字段\n",
    "                                                'Username','User_displayname', 'User_id', 'User_profile_description', 'User_description_link', 'User_verified',\n",
    "                                                'User_created', 'User_followers_count', 'User_friends_count', 'User_statuses_count', 'User_favourites_count',\n",
    "                                                'User_listed_count', 'User_media_count', 'User_location', 'User_protected', 'User_profile_link', 'User_profile_image_url',\n",
    "                                                'User_profile_banner_url', 'User_label' #user 相关的字段\n",
    "                                              ])\n",
    "    name = dates[i] +'_tweets.csv' \n",
    "    tweets_df.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "796129e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T07:16:21.371774Z",
     "start_time": "2022-11-15T07:16:20.255153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    clear(wait=True)\n",
    "    print(i, flush=True)\n",
    "    time.sleep(0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "923a4678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T07:20:33.115964Z",
     "start_time": "2022-11-15T07:20:33.091808Z"
    }
   },
   "outputs": [],
   "source": [
    "name = dates[0] +'_tweets.csv' \n",
    "tweets_df.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e38b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T10:53:25.827678Z",
     "start_time": "2022-11-15T10:53:25.827678Z"
    }
   },
   "outputs": [],
   "source": [
    "name = dates[i] +'_tweets(notfull).csv' \n",
    "tweets_df.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4efff175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T10:54:14.923588Z",
     "start_time": "2022-11-15T10:54:14.884692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89981497\n",
      "41498 tweets have been scraped\n",
      "41498 tweets have been scraped\n"
     ]
    }
   ],
   "source": [
    "print(sum(lenths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6de2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
